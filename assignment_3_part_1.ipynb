{
  "cells": [
    {
      "metadata": {
        "id": "cf4d8c9b006ada45"
      },
      "cell_type": "markdown",
      "source": [
        "## <center>CSE 546: Reinforcement Learning</center>\n",
        "### <center>Prof. Alina Vereshchaka</center>\n",
        "#### <center>Fall 2025</center>\n",
        "\n",
        "Welcome to the Assignment 3, Part 1: Introduction to Actor-Critic Methods! It includes the implementation of simple actor and critic networks and best practices used in modern Actor-Critic algorithms."
      ],
      "id": "cf4d8c9b006ada45"
    },
    {
      "metadata": {
        "id": "9d7a6d891e2fb312"
      },
      "cell_type": "markdown",
      "source": [
        "## Section 0: Setup and Imports"
      ],
      "id": "9d7a6d891e2fb312"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53473293aa9daf8e",
        "outputId": "ae68efc1-dbb3-43e7-a078-5c361f9213a8"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "\n",
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "id": "53473293aa9daf8e",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b8b84780d30>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "metadata": {
        "id": "2a3d9c34ff222994"
      },
      "cell_type": "markdown",
      "source": [
        "## Section 1: Actor-Critic Network Architectures and Loss Computation\n",
        "\n",
        "In this section, you will explore two common architectural designs for Actor-Critic methods and implement their corresponding loss functions using dummy tensors. These architectures are:\n",
        "- A. Completely separate actor and critic networks\n",
        "- B. A shared network with two output heads\n",
        "\n",
        "Both designs are widely used in practice. Shared networks are often more efficient and generalize better, while separate networks offer more control and flexibility.\n",
        "\n",
        "---\n"
      ],
      "id": "2a3d9c34ff222994"
    },
    {
      "metadata": {
        "id": "971fa7887dd4f858"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 1a â€“ Separate Actor and Critic Networks with Loss Function\n",
        "\n",
        "Define a class `SeparateActorCritic`. Your goal is to:\n",
        "- Create two completely independent neural networks: one for the actor and one for the critic.\n",
        "- The actor should output a probability distribution over discrete actions (use `nn.Softmax`).\n",
        "- The critic should output a single scalar value.\n",
        "\n",
        " Use `nn.ReLU()` as your activation function. Include at least one hidden layer of reasonable width (e.g. 64 or 128 units).\n",
        "\n",
        "```python\n",
        "# TODO: Define SeparateActorCritic class\n",
        "```\n",
        "\n",
        " Next, simulate training using dummy tensors:\n",
        "1. Generate dummy tensors for log-probabilities, returns, estimated values, and entropies.\n",
        "2. Compute the actor loss using the advantage (return - value).\n",
        "3. Compute the critic loss as mean squared error between values and returns.\n",
        "4. Use a single optimizer for both the Actor and the Critic. In this case, combine the actor and critic losses into a total loss and perform backpropagation.\n",
        "5. Use a separate optimizers for both the Actor and the Critic. In this case, keep the actor and critic losses separate and perform backpropagation.\n",
        "\n",
        "```python\n",
        "# TODO: Simulate loss computation and backpropagation\n",
        "```\n",
        "\n",
        "ðŸ”— Helpful references:\n",
        "- PyTorch Softmax: https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n",
        "- PyTorch MSE Loss: https://pytorch.org/docs/stable/generated/torch.nn.functional.mse_loss.html\n",
        "\n",
        "---"
      ],
      "id": "971fa7887dd4f858"
    },
    {
      "metadata": {
        "id": "dd6b81ed1791e4e6"
      },
      "cell_type": "code",
      "source": [
        "# TODO: Define a class SeparateActorCritic with separate networks for actor and critic\n",
        "\n",
        "# BEGIN_YOUR_CODE\n",
        "class SeparateActorCritic(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_size = 128):\n",
        "    super(SeparateActorCritic, self).__init__()\n",
        "\n",
        "    # Actor\n",
        "    self.actor_fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.actor_fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    # Critic\n",
        "    self.critic_fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.critic_fc2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    actor = F.relu(self.actor_fc1(x))\n",
        "    actor_out = self.softmax(self.actor_fc2(actor))\n",
        "\n",
        "    critic = F.relu(self.critic_fc1(x))\n",
        "    critic_out = self.critic_fc2(critic)\n",
        "\n",
        "    return actor_out, critic_out\n",
        "\n",
        "# END_YOUR_CODE"
      ],
      "id": "dd6b81ed1791e4e6",
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simulate training using dummy tensors"
      ],
      "metadata": {
        "id": "6eauU5RAMRcK"
      },
      "id": "6eauU5RAMRcK"
    },
    {
      "cell_type": "code",
      "source": [
        "log_prob = torch.randn(7, requires_grad=True)\n",
        "returns = torch.randn(7)\n",
        "values = torch.randn(7, requires_grad=True)\n",
        "entropy = torch.rand(1)\n",
        "\n",
        "# Advantage\n",
        "advantage = returns - values.detach()\n",
        "\n",
        "# Loss\n",
        "actor_loss = -(log_prob * advantage).mean()\n",
        "critic_loss = F.mse_loss(values, returns)"
      ],
      "metadata": {
        "id": "NR0Kd4WJCcig"
      },
      "id": "NR0Kd4WJCcig",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Single optimizer for both actor and critic"
      ],
      "metadata": {
        "id": "4oIvaEFAMWmU"
      },
      "id": "4oIvaEFAMWmU"
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss = actor_loss + critic_loss\n",
        "optimizer = optim.Adam([log_prob, values], lr=0.001)\n",
        "optimizer.zero_grad()\n",
        "total_loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(f\"Total loss for the single optimizer:  {total_loss.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeE6WGesIy1Y",
        "outputId": "a6fda5fb-3aeb-41a2-81e9-f6c0e97e0f58"
      },
      "id": "qeE6WGesIy1Y",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total loss for the single optimizer:  3.693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seperater optimizer for  actor and critic"
      ],
      "metadata": {
        "id": "wtcrtfw2Mbvr"
      },
      "id": "wtcrtfw2Mbvr"
    },
    {
      "cell_type": "code",
      "source": [
        "actor_loss = -(log_prob * advantage).mean()\n",
        "critic_loss = F.mse_loss(values, returns)\n",
        "\n",
        "# Separate optimizers\n",
        "actor_optimizer = optim.Adam([log_prob], lr=0.001)\n",
        "critic_optimizer = optim.Adam([values], lr=0.001)\n",
        "\n",
        "actor_optimizer.zero_grad()\n",
        "actor_loss.backward()\n",
        "actor_optimizer.step()\n",
        "\n",
        "critic_optimizer.zero_grad()\n",
        "critic_loss.backward()\n",
        "critic_optimizer.step()\n",
        "\n",
        "print(f\"Actor loss:  {actor_loss.item():.3f}\")\n",
        "print(f\"Critic loss: {critic_loss.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_CpZztfIz-T",
        "outputId": "36b9a84a-768e-438f-cabf-cfdee5d01ff9"
      },
      "id": "D_CpZztfIz-T",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actor loss:  1.298\n",
            "Critic loss: 2.392\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eb8e90c88108cd2e"
      },
      "cell_type": "markdown",
      "source": [
        "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
        "\n",
        "YOUR ANSWER:\n",
        "\n",
        "Sharing some layers can have many advantages that are discussed below after the implementation of the `SharedActorCritic`. However, the completely seperate architecture can make learning more stable, as the actor and critic gradients are isolated from each other.\n",
        "\n",
        "---"
      ],
      "id": "eb8e90c88108cd2e"
    },
    {
      "metadata": {
        "id": "64081a606b93029d"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 1b â€“ Shared Network with Actor and Critic Heads + Loss Function\n",
        "\n",
        "Now define a class `SharedActorCritic`:\n",
        "- Build a shared base network (e.g., linear layer + ReLU)\n",
        "- Create two heads: one for actor (output action probabilities) and one for critic (output state value)\n",
        "\n",
        "```python\n",
        "# TODO: Define SharedActorCritic class\n",
        "```\n",
        "\n",
        "Then:\n",
        "1. Pass a dummy input tensor through the model to obtain action probabilities and value.\n",
        "2. Simulate dummy rewards and compute advantage.\n",
        "3. Compute the actor and critic losses, combine them, and backpropagate.\n",
        "\n",
        "```python\n",
        "# TODO: Simulate shared network loss computation and backpropagation\n",
        "```\n",
        "\n",
        " Use `nn.Softmax` for actor output and `nn.Linear` for scalar critic output.\n",
        "\n",
        "ðŸ”— More reading:\n",
        "- Policy Gradient Methods: https://spinningup.openai.com/en/latest/algorithms/vpg.html\n",
        "- Actor-Critic Overview: https://www.tensorflow.org/agents/tutorials/6_reinforce_tutorial\n",
        "- PyTorch Categorical Distribution: https://pytorch.org/docs/stable/distributions.html#categorical\n",
        "\n",
        "---"
      ],
      "id": "64081a606b93029d"
    },
    {
      "metadata": {
        "id": "a48f882fff11aecc"
      },
      "cell_type": "code",
      "source": [
        "# BEGIN_YOUR_CODE\n",
        "\n",
        "class SharedActorCritic(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_size = 128):\n",
        "    super(SharedActorCritic, self).__init__()\n",
        "\n",
        "    self.shared_fc = nn.Linear(input_size, hidden_size)\n",
        "    self.shared_relu = nn.ReLU()\n",
        "\n",
        "    self.actor_head = nn.Linear(hidden_size, output_size)\n",
        "    self.critic_head = nn.Linear(hidden_size, 1)\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    shared = self.shared_relu(self.shared_fc(x))\n",
        "    actor_out = self.softmax(self.actor_head(shared))\n",
        "    critic_out = self.critic_head(shared)\n",
        "\n",
        "    return actor_out, critic_out\n",
        "\n",
        "# END_YOUR_CODE"
      ],
      "id": "a48f882fff11aecc",
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 7\n",
        "input_size = 8\n",
        "output_size = 2\n",
        "\n",
        "model = SharedActorCritic(input_size, output_size)\n",
        "obs = torch.randn(batch_size, input_size)\n",
        "\n",
        "# Forward pass\n",
        "actor_out, critic_out = model(obs)\n",
        "\n",
        "returns = torch.randn(batch_size)\n",
        "advantage = returns - critic_out.detach().squeeze()\n",
        "\n",
        "# losses\n",
        "log_probs = torch.log(actor_out)\n",
        "actor_loss = -(log_probs.mean(dim=1) * advantage).mean()\n",
        "critic_loss = F.mse_loss(critic_out.squeeze(), returns)\n",
        "\n",
        "total_loss = actor_loss + critic_loss"
      ],
      "metadata": {
        "id": "zaKA4RvJRX9J"
      },
      "id": "zaKA4RvJRX9J",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "total_loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(\"Actor output (probabilities):\")\n",
        "print(actor_out)\n",
        "print(\"\\nCritic output:\")\n",
        "print(critic_out)\n",
        "print(f\"\\nActor loss:  {actor_loss.item():.3f}\")\n",
        "print(f\"Critic loss: {critic_loss.item():.3f}\")\n",
        "print(f\"Total loss:  {total_loss.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ84YQZ0RXy8",
        "outputId": "40ebefb2-6ed7-4244-9645-9ff3c96e4526"
      },
      "id": "AJ84YQZ0RXy8",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actor output (probabilities):\n",
            "tensor([[0.4978, 0.5022],\n",
            "        [0.3885, 0.6115],\n",
            "        [0.4719, 0.5281],\n",
            "        [0.6003, 0.3997],\n",
            "        [0.5541, 0.4459],\n",
            "        [0.5080, 0.4920],\n",
            "        [0.6093, 0.3907]], grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "Critic output:\n",
            "tensor([[ 0.1806],\n",
            "        [-0.2898],\n",
            "        [ 0.0814],\n",
            "        [ 0.1792],\n",
            "        [ 0.0350],\n",
            "        [-0.0008],\n",
            "        [ 0.2132]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Actor loss:  0.082\n",
            "Critic loss: 0.322\n",
            "Total loss:  0.404\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "a974e302d1fdb028"
      },
      "cell_type": "markdown",
      "source": [
        "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
        "\n",
        "YOUR ANSWER:\n",
        "\n",
        "In this `SharedActorCritic` setup, the actor and critic share the base layers, and have seperate heads for output. This sharing setup may help reduce the total number of learnable paramaters, improving the efficiency, and reducing the training time.\n",
        "\n",
        "---"
      ],
      "id": "a974e302d1fdb028"
    },
    {
      "metadata": {
        "id": "eb645eb009b85b1c"
      },
      "cell_type": "markdown",
      "source": [
        "## Section 2: Auto-Adaptive Network Setup for Environments\n",
        "\n",
        "You will now create a function that builds a shared actor-critic network that adapts to any Gymnasium environment. This function should inspect the environment and build input/output layers accordingly."
      ],
      "id": "eb645eb009b85b1c"
    },
    {
      "metadata": {
        "id": "4223b6ddf43abee5"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 2: Auto-generate Input and Output Layers\n",
        "Write a function `create_shared_network(env)` that constructs a neural network using the following rules:\n",
        "- The input layer should match the environment's observation space.\n",
        "- The output layer for the **actor** should depend on the action space:\n",
        "  - For discrete actions: output probabilities using `nn.Softmax`.\n",
        "  - For continuous actions: output mean and log std for a Gaussian distribution.\n",
        "- The **critic** always outputs a single scalar value.\n",
        "\n",
        "```python\n",
        "# TODO: Define function `create_shared_network(env)`\n",
        "```\n",
        "\n",
        "#### Environments to Support:\n",
        "Test your function with the following environments:\n",
        "1. `CliffWalking-v0` (Use one-hot encoding for discrete integer observations.)\n",
        "2. `LunarLander-v3` (Standard Box space for observations and discrete actions.)\n",
        "3. `PongNoFrameskip-v4` (Use gym wrappers for Atari image preprocessing.)\n",
        "4. `HalfCheetah-v5` (Continuous observation and continuous action.)\n",
        "\n",
        "```python\n",
        "# TODO: Loop through environments and test `create_shared_network`\n",
        "```\n",
        "\n",
        "Hint: Use `gym.spaces` utilities to determine observation/action types dynamically.\n",
        "\n",
        "ðŸ”— Observation/Action Space Docs:\n",
        "- https://gymnasium.farama.org/api/spaces/\n",
        "\n",
        "---"
      ],
      "id": "4223b6ddf43abee5"
    },
    {
      "metadata": {
        "id": "d6d249ff9277403a"
      },
      "cell_type": "code",
      "source": [
        "# BEGIN_YOUR_CODE\n",
        "\n",
        "def create_shared_network(env):\n",
        "  observ_space = env.observation_space\n",
        "  action_space = env.action_space\n",
        "\n",
        "  if isinstance(observ_space, gym.spaces.Discrete):\n",
        "    input_size = observ_space.n\n",
        "    one_hot_encode = True\n",
        "  else:\n",
        "    input_size = int(np.prod(observ_space.shape))\n",
        "    one_hot_encode = False\n",
        "\n",
        "  if isinstance(action_space, gym.spaces.Discrete):\n",
        "    output_size = action_space.n\n",
        "    continuous = False\n",
        "  else:\n",
        "    output_size = action_space.shape[0]\n",
        "    continuous = True\n",
        "\n",
        "  class SharedActorCritic(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size = 128):\n",
        "      super(SharedActorCritic, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.output_size = output_size\n",
        "      self.one_hot_encode = one_hot_encode\n",
        "      self.continuous = continuous\n",
        "\n",
        "      # Shared layesr\n",
        "      self.shared_fc = nn.Linear(input_size, hidden_size)\n",
        "      self.shared_relu = nn.ReLU()\n",
        "\n",
        "      # actor\n",
        "      if self.continuous:\n",
        "        self.mean_head = nn.Linear(hidden_size, output_size)\n",
        "        self.log_std = nn.Parameter(torch.zeros(output_size))\n",
        "      else:\n",
        "        self.actor_head = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "      # critic\n",
        "      self.critic_head = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      if self.one_hot_encode:\n",
        "        if x.dim() > 1:\n",
        "          x = x.squeeze(-1)\n",
        "        x = F.one_hot(x.long(), num_classes=self.input_size).float()\n",
        "      else:\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "      # shared\n",
        "      shared = self.shared_relu(self.shared_fc(x))\n",
        "\n",
        "      # actor\n",
        "      if self.continuous:\n",
        "        mean = self.mean_head(shared)\n",
        "        log_std = self.log_std.expand_as(mean)\n",
        "        actor_out = (mean, log_std)\n",
        "      else:\n",
        "        actor_out = self.softmax(self.actor_head(shared))\n",
        "\n",
        "      # critic\n",
        "      critic_out = self.critic_head(shared)\n",
        "\n",
        "      return actor_out, critic_out\n",
        "\n",
        "  return SharedActorCritic(input_size, output_size)\n",
        "\n",
        "# END_YOUR_CODE"
      ],
      "id": "d6d249ff9277403a",
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "print(gym.make(\"CliffWalking-v1\").observation_space)\n",
        "print(gym.make(\"LunarLander-v3\").observation_space)\n",
        "print(gym.make(\"PongNoFrameskip-v4\").observation_space)\n",
        "print(gym.make(\"HalfCheetah-v5\").observation_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "CTFyJSaHPUgq",
        "outputId": "e287246a-f30b-4160-ee92-99ce9f09519e"
      },
      "id": "CTFyJSaHPUgq",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(48)\n",
            "Box([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
            "  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n",
            "  1.         1.       ], (8,), float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameNotFound",
          "evalue": "Environment `PongNoFrameskip` doesn't exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2700578354.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CliffWalking-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LunarLander-v3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PongNoFrameskip-v4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HalfCheetah-v5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;31m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0menv_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(env_id)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menv_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0m_check_version_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         raise error.Error(\n\u001b[1;32m    528\u001b[0m             \u001b[0;34mf\"No registered env with id: {env_name}. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0m_check_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0msuggestion_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\" Did you mean: `{suggestion[0]}`?\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     raise error.NameNotFound(\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;34mf\"Environment `{name}` doesn't exist{namespace_msg}.{suggestion_msg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     )\n",
            "\u001b[0;31mNameNotFound\u001b[0m: Environment `PongNoFrameskip` doesn't exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.wrappers import AtariPreprocessing, FrameStack\n",
        "\n",
        "env_names = [\"CliffWalking-v1\", \"LunarLander-v3\", \"HalfCheetah-v5\"]\n",
        "\n",
        "for name in env_names:\n",
        "    print(f\"\\n\\nTesting the {name} Environment\")\n",
        "\n",
        "    if name == \"PongNoFrameskip-v4\":\n",
        "        env = gym.make(name,  frameskip=1)\n",
        "        env = AtariPreprocessing(env)\n",
        "        env = FrameStack(env, 4)\n",
        "    else:\n",
        "        env = gym.make(name)\n",
        "\n",
        "    network = create_shared_network(env)\n",
        "    state, info = env.reset()\n",
        "\n",
        "    # Get state as tensor\n",
        "    state_tensor = torch.tensor(state).unsqueeze(0).float()\n",
        "\n",
        "    # Forward pass\n",
        "    actor_out, critic_out = network(state_tensor)\n",
        "\n",
        "    print(\"Actor Output:\", actor_out)\n",
        "    print(\"\\nCritic Output:\", critic_out)\n",
        "    print(f'\\n{network}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n082S-PxJJy4",
        "outputId": "8508ed63-0f15-468c-e4df-083e56805caa"
      },
      "id": "n082S-PxJJy4",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Testing the CliffWalking-v1 Environment\n",
            "Actor Output: tensor([[0.2535, 0.2293, 0.2620, 0.2553]], grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "Critic Output: tensor([[-0.0076]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "SharedActorCritic(\n",
            "  (shared_fc): Linear(in_features=48, out_features=128, bias=True)\n",
            "  (shared_relu): ReLU()\n",
            "  (actor_head): Linear(in_features=128, out_features=4, bias=True)\n",
            "  (softmax): Softmax(dim=-1)\n",
            "  (critic_head): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "Testing the LunarLander-v3 Environment\n",
            "Actor Output: tensor([[0.2468, 0.2497, 0.2690, 0.2345]], grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "Critic Output: tensor([[-0.1622]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "SharedActorCritic(\n",
            "  (shared_fc): Linear(in_features=8, out_features=128, bias=True)\n",
            "  (shared_relu): ReLU()\n",
            "  (actor_head): Linear(in_features=128, out_features=4, bias=True)\n",
            "  (softmax): Softmax(dim=-1)\n",
            "  (critic_head): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "Testing the HalfCheetah-v5 Environment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DependencyNotInstalled",
          "evalue": "MuJoCo is not installed, run `pip install \"gymnasium[mujoco]\"`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmujoco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mujoco'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-669984776.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_shared_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;31m# Assume it's a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0menv_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_env_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;31m# Determine if to use the rendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36mload_env_creator\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \"\"\"\n\u001b[1;32m    543\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/mujoco/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgymnasium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmujoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmujoco_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMujocoEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgymnasium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmujoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmujoco_rendering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMujocoRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmujoco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     raise error.DependencyNotInstalled(\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;34m'MuJoCo is not installed, run `pip install \"gymnasium[mujoco]\"`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     ) from e\n",
            "\u001b[0;31mDependencyNotInstalled\u001b[0m: MuJoCo is not installed, run `pip install \"gymnasium[mujoco]\"`"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4ccd13f0b62b30ff"
      },
      "cell_type": "markdown",
      "source": [
        "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
        "\n",
        "YOUR ANSWER:"
      ],
      "id": "4ccd13f0b62b30ff"
    },
    {
      "metadata": {
        "id": "ee2dd81024ce246a"
      },
      "cell_type": "code",
      "source": [],
      "id": "ee2dd81024ce246a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "b39c886fa536a639"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 3: Write Observation Normalization Function\n",
        "Create a function `normalize_observation(obs, env)` that:\n",
        "- Checks if the observation space is `Box` and has `low` and `high` attributes.\n",
        "- If so, normalize the input observation.\n",
        "- Otherwise, return the observation unchanged.\n",
        "\n",
        "```python\n",
        "# TODO: Define `normalize_observation(obs, env)`\n",
        "```\n",
        "\n",
        "Test this function with observations from:\n",
        "- `LunarLander-v3`\n",
        "- `PongNoFrameskip-v4`\n",
        "\n",
        "Note: Atari observations are image arrays. Normalize pixel values to [0, 1]. For LunarLander-v3, the different elements in the observation vector have different ranges. Normalize them to [0, 1] using the `low` and `high` attributes of the observation space.\n",
        "\n",
        "\n",
        "---"
      ],
      "id": "b39c886fa536a639"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install -y swig\n",
        "\n",
        "!pip install \"gymnasium[box2d]\" box2d box2d-py\n"
      ],
      "metadata": {
        "id": "n0L7gwlpxclN"
      },
      "id": "n0L7gwlpxclN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gymnasium[atari,accept-rom-license]\""
      ],
      "metadata": {
        "id": "576LkKcz0ofx"
      },
      "id": "576LkKcz0ofx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gymnasium[atari] -q\n",
        "# !pip install gymnasium[accept-rom-license] -q\n",
        "!pip install \"gym[atari,accept-rom-license]\" ale-py autorom\n",
        "!AutoROM --accept-license\n",
        "\n"
      ],
      "metadata": {
        "id": "RBSxH6DOOxQT"
      },
      "id": "RBSxH6DOOxQT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium.envs.registration import registry\n",
        "pong_envs = [env_id for env_id in registry.keys() if \"Pong\" in env_id]\n",
        "print(\"Pong env IDs:\", pong_envs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w0xNUNyNzRg",
        "outputId": "7c7c0340-83be-4854-ea72-4497cf259b7d"
      },
      "id": "5w0xNUNyNzRg",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pong env IDs: []\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fc7ee06112cf7d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "8fae8a63-c6a5-4d30-e1ed-52b80cea3152"
      },
      "cell_type": "code",
      "source": [
        "# BEGIN_YOUR_CODE\n",
        "\n",
        "def normalize_observation(obs, env):\n",
        "    obs_space = env.observation_space\n",
        "\n",
        "    if not isinstance(obs_space, gym.spaces.Box):\n",
        "        return obs\n",
        "\n",
        "    is_tensor = isinstance(obs, torch.Tensor)\n",
        "    if is_tensor:\n",
        "        obs_np = obs.detach().cpu().numpy().astype(np.float32)\n",
        "    else:\n",
        "        obs_np = np.array(obs, dtype=np.float32)\n",
        "\n",
        "    low = obs_space.low\n",
        "    high = obs_space.high\n",
        "\n",
        "    if not (np.all(np.isfinite(low)) and np.all(np.isfinite(high))):\n",
        "        return obs\n",
        "\n",
        "    is_pixel_space = (\n",
        "        np.issubdtype(obs_space.dtype, np.integer)\n",
        "        or (low.min() == 0 and high.max() == 255)\n",
        "    )\n",
        "    if is_pixel_space:\n",
        "        norm = obs_np / 255.0\n",
        "    else:\n",
        "        denom = (high - low)\n",
        "        denom[denom == 0] = 1.0\n",
        "        norm = 2.0 * (obs_np - low) / denom - 1.0\n",
        "\n",
        "    if is_tensor:\n",
        "        norm_tensor = torch.from_numpy(norm).to(dtype=obs.dtype, device=obs.device)\n",
        "        return norm_tensor\n",
        "    else:\n",
        "        return norm.astype(np.float32)\n",
        "\n",
        "# LunarLander-v3\n",
        "ll_env = gym.make(\"LunarLander-v3\")\n",
        "ll_obs, ll_info = ll_env.reset()\n",
        "ll_obs_norm = normalize_observation(ll_obs, ll_env)\n",
        "print(\"LunarLander-v3:\")\n",
        "print(\"  raw obs:        \", ll_obs)\n",
        "print(\"  normalized obs: \", ll_obs_norm)\n",
        "print(\"  normalized range: [\", ll_obs_norm.min(), \",\", ll_obs_norm.max(), \"]\\n\")\n",
        "\n",
        "# PongNoFrameskip-v4\n",
        "from gym.wrappers import AtariPreprocessing, FrameStack\n",
        "\n",
        "pong_env = gym.make(\"PongNoFrameskip-v4\", frameskip=1)\n",
        "pong_env = AtariPreprocessing(pong_env, grayscale_obs=True, scale_obs=False)\n",
        "pong_env = FrameStack(pong_env, 4)\n",
        "\n",
        "pong_obs, pong_info = pong_env.reset()\n",
        "pong_obs_np = np.array(pong_obs)\n",
        "pong_obs_norm = normalize_observation(pong_obs_np, pong_env)\n",
        "\n",
        "print(\"PongNoFrameskip-v4:\")\n",
        "print(\"  raw obs shape:        \", pong_obs_np.shape, \"dtype:\", pong_obs_np.dtype)\n",
        "print(\"  normalized obs shape: \", pong_obs_norm.shape)\n",
        "print(\"  normalized range: [\", pong_obs_norm.min(), \",\", pong_obs_norm.max(), \"]\")\n",
        "\n",
        "# END_YOUR_CODE"
      ],
      "id": "fc7ee06112cf7d29",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LunarLander-v3:\n",
            "  raw obs:         [-0.00403442  1.3995736  -0.40865213 -0.5043002   0.00468159  0.09256576\n",
            "  0.          0.        ]\n",
            "  normalized obs:  [-1.6137958e-03  5.5982947e-01 -4.0865242e-02 -5.0430000e-02\n",
            "  7.4505806e-04  9.2566013e-03 -1.0000000e+00 -1.0000000e+00]\n",
            "  normalized range: [ -1.0 , 0.5598295 ]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameNotFound",
          "evalue": "Environment `PongNoFrameskip` doesn't exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2230466017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAtariPreprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrameStack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mpong_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PongNoFrameskip-v4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframeskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mpong_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAtariPreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpong_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale_obs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_obs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mpong_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpong_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;31m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0menv_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(env_id)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menv_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0m_check_version_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         raise error.Error(\n\u001b[1;32m    528\u001b[0m             \u001b[0;34mf\"No registered env with id: {env_name}. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0m_check_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0msuggestion_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\" Did you mean: `{suggestion[0]}`?\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     raise error.NameNotFound(\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;34mf\"Environment `{name}` doesn't exist{namespace_msg}.{suggestion_msg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     )\n",
            "\u001b[0;31mNameNotFound\u001b[0m: Environment `PongNoFrameskip` doesn't exist."
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "metadata": {
        "id": "501ed2a6e7ca7a7b"
      },
      "cell_type": "markdown",
      "source": [
        "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
        "\n",
        "YOUR ANSWER:"
      ],
      "id": "501ed2a6e7ca7a7b"
    },
    {
      "metadata": {
        "id": "78211b617a843f62"
      },
      "cell_type": "code",
      "source": [],
      "id": "78211b617a843f62",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "6b5fb5353307f514"
      },
      "cell_type": "markdown",
      "source": [
        "## Section 4: Gradient Clipping\n",
        "\n",
        "To prevent exploding gradients, it's common practice to clip gradients before optimizer updates.\n",
        "\n",
        "### Task 4: Clip Gradients for Actor-Critic Networks\n",
        "Use dummy tensors and apply gradient clipping with the following PyTorch method:\n",
        "```python\n",
        "# During training, after loss.backward():\n",
        "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "```\n",
        "\n",
        "Reuse the loss computation from Task 1a or 1b. After computing the gradients, apply gradient clipping.\n",
        "Print the gradient norm before and after clipping to verify itâ€™s applied.\n",
        "\n",
        "ðŸ”— PyTorch Docs: https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html\n",
        "\n",
        "\n",
        "---"
      ],
      "id": "6b5fb5353307f514"
    },
    {
      "metadata": {
        "id": "7327507fb6e803ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28c0488-28d8-427c-da80-2093b555c9de"
      },
      "cell_type": "code",
      "source": [
        "# BEGIN_YOUR_CODE\n",
        "\n",
        "batch_size = 7\n",
        "input_size = 8\n",
        "output_size = 2\n",
        "model = SharedActorCritic(input_size, output_size)\n",
        "\n",
        "obs = torch.randn(batch_size, input_size)\n",
        "returns = torch.randn(batch_size)\n",
        "\n",
        "actor_out, critic_out = model(obs)\n",
        "\n",
        "advantage = returns - critic_out.detach().squeeze()\n",
        "log_probs = torch.log(actor_out + 1e-8)\n",
        "actor_loss = -(log_probs.mean(dim=1) * advantage).mean()\n",
        "critic_loss = F.mse_loss(critic_out.squeeze(), returns)\n",
        "total_loss = actor_loss + critic_loss\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "total_loss.backward()\n",
        "\n",
        "print(\"Single Optimizer Training Step:\")\n",
        "print(f\"Actor Loss: {actor_loss.item()}\")\n",
        "print(f\"Critic Loss: {critic_loss.item()}\")\n",
        "print(f\"Total Loss: {total_loss.item()}\")\n",
        "\n",
        "total_norm_before = 0.0\n",
        "for p in model.parameters():\n",
        "    if p.grad is not None:\n",
        "        param_norm = p.grad.data.norm(2)\n",
        "        total_norm_before += param_norm.item() ** 2\n",
        "total_norm_before = total_norm_before ** 0.5\n",
        "\n",
        "print(f\"Gradient norm before clipping: {total_norm_before}\")\n",
        "\n",
        "max_grad_norm = 0.5\n",
        "grad_norm_reported = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
        "\n",
        "print(f\"Gradient norm reported by clip_grad_norm_ (before clipping): {grad_norm_reported}\")\n",
        "\n",
        "total_norm_after = 0.0\n",
        "for p in model.parameters():\n",
        "    if p.grad is not None:\n",
        "        param_norm = p.grad.data.norm(2)\n",
        "        total_norm_after += param_norm.item() ** 2\n",
        "total_norm_after = total_norm_after ** 0.5\n",
        "\n",
        "print(f\"Gradient norm after clipping: {total_norm_after}\")\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "# END_YOUR_CODE"
      ],
      "id": "7327507fb6e803ad",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Optimizer Training Step:\n",
            "Actor Loss: 0.04275137931108475\n",
            "Critic Loss: 0.6760669946670532\n",
            "Total Loss: 0.7188183665275574\n",
            "Gradient norm before clipping: 2.375636694040338\n",
            "Gradient norm reported by clip_grad_norm_ (before clipping): 2.375636577606201\n",
            "Gradient norm after clipping: 0.499999797680716\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "metadata": {
        "id": "9952750fa74cd487"
      },
      "cell_type": "markdown",
      "source": [
        "### Discuss the motivation behind each setup and when it may be preferred in practice.\n",
        "\n",
        "YOUR ANSWER:\n",
        "\n",
        "\n",
        "The code uses a shared SharedActorCritic network with one optimizer step to show how gradient clipping works. The network takes an 8-dimensional observation, passes it through shared layers, and then splits into two heads: one head outputs action probabilities (actor), and the other predicts a value estimate (critic). The actor loss is computed using a policy-gradient style term with an advantage (return - value), and the critic loss is the mean-squared error between the predicted values and the target returns. These two losses are added into a single total loss, and total_loss.backward() is called so that gradients are computed for all parts of the model.\n",
        "\n",
        "After backpropagation, the code calculates the global L2 norm of all gradients before clipping, applies torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5), and then measures the gradient norm again. In the example run, the gradient norm starts at about 3.40 and is reduced to around 0.5 after clipping. This shows that gradient clipping is actually limiting the size of the update. This kind of setupâ€”a shared actorâ€“critic network with a single optimizer and gradient norm clippingâ€”is useful in reinforcement learning when gradients can suddenly become large due to noisy returns or advantages. Clipping keeps the training step under control and helps prevent unstable updates, while still allowing the model to learn from both the actor and critic losses at the same time.\n",
        "\n"
      ],
      "id": "9952750fa74cd487"
    },
    {
      "metadata": {
        "id": "557a9303f5a1c863"
      },
      "cell_type": "code",
      "source": [],
      "id": "557a9303f5a1c863",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f4cff31e6c6e7e4a"
      },
      "cell_type": "markdown",
      "source": [
        "If you are working in a team, provide a contribution summary.\n",
        "| Team Member | Step# | Contribution (%) |\n",
        "|---|---|---|\n",
        "| Ziyad Shahin  | Task 1 |  100% |\n",
        "| Ziyad Shahin  | Task 2 |  100%  |\n",
        "|  Jahnavi Gubbala | Task 3 |  100% |\n",
        "|  Jahnavi Gubbala | Task 4 |  100% |\n",
        "|   | **Total** |   |\n"
      ],
      "id": "f4cff31e6c6e7e4a"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "REhQ46sPYCj3"
      },
      "id": "REhQ46sPYCj3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}